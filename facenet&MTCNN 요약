FaceNet
https://hwangtoemat.github.io/paper-review/2020-04-02-FaceNet-%EB%82%B4%EC%9A%A9/
https://blog.naver.com/tmdwhd619/222872031701
https://butter-shower.tistory.com/233
https://cake.tistory.com/44
https://marades.tistory.com/9

FACENET 모델
facenet 논문 링크 https://arxiv.org/abs/1503.03832


FaceNet 모델 정의

FaceNet은 플로리안 스크로프와 Google에서 2015년 “FaceNet: 얼굴 인식 및 클러스터링용 통합 임베딩.” 논문을 통해 제시한 얼굴 인식 시스템입니다.

FaceNet은 각 이미지(얼굴 이미지)를 128차원으로 임베딩하여 유클리드 공간에서 이미지간 거리를 통해 분류하는 모델입니다.

accuracy 99.63%를 기록함

	#안넣으셔도 됩니당
 embedding : 언어나 이미지를 수치화된 여러차원의 데이터로
 변환하는 작업
유클리드 공간 : 직선에 평행한 직선은 단 하나만 존재하는 공
Facenet의 주요 기능

1. Face-Verification(동일인물인지)
2. Recognition(누구인지)
3. Clustering(공통되는 사람들 찾기)
Face-Verification: 두 임베딩 사이의 거리 일정 차이를 넘는지 동일인물인지 판단 1:1 문제
Recognition: k-NN Classfication문제 1:N 문제 여러명중에 특정인물 찾기
Clustering: k-means나 집적(agglomerative) clustering ex) 동물상


FaceNet은 얼굴 이미지에서 얼굴 유사성 척도와 얼마나 직접적으로 일치하는지 거리를 측정하는 밀집 유클리드 공간으로의 매핑을 직접 학습합니다.


FaceNet은 얼굴 이미지로 부터 유클리드 공간

(distance : measutre of face similarity)의 관계를 학습한다


FaceNet의 주요 특징과 장점
얼굴 사진이 주어지면,
이것을 직접적으로 n차원의 Euclidean space상의 벡터로 mapping 시킬 수 있다는 점
훈련을 시킬 때에 'triplet loss'를 사용한다는 점
이로부터 오는 장점은 아래와 같습니다.

output 형태가 embedding vector이기 때문에,
이전 모델들과는 달리 embedding vector을 직접적으로 optimize 한다는 점 -> 모델 사이즈와 요구 CPU 연산을 줄였다.
적은 차원의 embedding vector를 가지고도 효과적으로 이미지를 표현해낼 수 있다는 점 -> 이전모델들은 1000단위의 차원이었는데 128차원으로 줄임



4.  FaceNet 모델 구조


위의 figure로부터
1. FaceNet는 deep convolution network의 구조를 가지며,
2.임베딩 공간의 squared L2 Distances(유클리드 거리의 제곱)을 이용하여서 얼굴 유사도를 구함  L2 정규화
즉 같은 사람의 얼굴은 적은 거리를 가지고 다른 사람일 경우 큰 거리를 가지게 된다.
3.최종 output은 embedding vector임을 알 수 있습니다.
4.그리고 모델은 triplet loss를 통해 학습을 진행함을 알 수 있습니다.



​
LMNN
FaceNet은 LMNN(Large margin nearest neighbor)을 기반으로 triplet loss를 이용하여 128차원 임베딩이 아웃풋이 되도록 곧바로 학습


triplet은 2개의 일치하는 얼굴과 하나의 다른 얼굴로 이루어져 있으며 loss는 

distance margin으로 일치하는 쪽을 불일치하는 쪽으로부터 분리해내는 데 초점을 두고 있다.

triplet loss(삼중항 손실)의 정의

이 모델은 세 개의 손실 함수를 통해 훈련된 심층 합성곱 신경망으로,
 같은 정체성에 대한 벡터가 더 비슷(더 가까운 거리)해지고, 
다른 정체성에 대한 벡터는 덜 비슷(더 먼 거리)해질 것입니다. 
모델의 중간 층에서 임베딩을 추출하는 대신 Facenet은 임베딩을 
직접 생성하기 위해 모델을 훈련하는 데 중점을 뒀다.


Triplet Loss에서는 어떤 한 사람(Anchor)과 같은 사람(Positive), 다른 사람(Negative)이 등장합니다. 학습시 미니 배치 안에서 anchor, positive, negative들이 임베딩된 값들의 유클리드 거리를 구해 아래와 같은 Loss 함수를 만듭니다.

대괄호 안의 첫번째 항이 의미하는 것은 anchor와 postivie와의 거리고, 두번째 항은 anchor와 negative와의 거리이며 α는 마진(하이퍼파라미터)을 의미합니다. 
따라서 L을 최소화한다는 것은 Positive와의 거리는 가까워지도록 하고 Negative와의 거리는 멀어지도록 하는 것입니다.

하지만 위의 식만을 사용할때 모든 anchor은 쌍을 이루게 되고 상대적으로 시간이 오래걸린다.
—--------

그래서 논문에서는 
Hard Positive(같은 사람이지만 다르게 보이는 사람)과 
Hard Negative(다른 사람이지만 닮은 사람)을 학습에 방해하는 요소로 두고 아래와 같이 제어를 했습니다.


Hard Positive의 경우에는 전부 학습을 진행했지만 
Hard Negative의 경우에는 세번째 식의 조건을 주어 이 조건을 만족하는 경우에만 학습을 진행하게 했습니다. 

# 안넣어도 괜찮습니당
-> embedding vector f(x)를 0으로 만들지 않는 Semi-hard negative data 사용

MTCNN(Multi-task CNN)

https://yeomko.tistory.com/16
https://github.com/davidsandberg/facenet/wiki#face-alignment-using-mtcnn
https://github.com/davidsandberg/facenet/wiki/Training-using-the-VGGFace2-dataset
MTCNN 논문 링크 : https://arxiv.org/abs/1604.02878

MTCNN 모델 정의
MTCNN 모델은 얼굴 감지를 위해 멀티태스킹 합성곱 신경망(MTCNN)을 사용하는 2016년에 발행된 얼굴 인식을 위한  최첨단 딥러닝 모델이다.

MTCNN의 주요 기능
face detection, face alignment, bounding box regression 세 가지 테스크를 동시에 학습시키는 joint learning 방식을 제안, 이를 통해 떠 빠른 속도와 높은 정확도를 달성

face detection : 얼굴을 검출
face alignment : 눈, 코, 입의 좌표를 알아냄
bounding box regression : 박스 위치 미세조정
> 위 세가지를 동시에

MTCNN 모델 구조
P-net
https://youtu.be/w4tigQn-7Jw


input 이미지를 단계별로 Resize하여 이미지 피라미드 구축
3단계에 거친 이미지 list를 만든다. -> 작은 얼굴도 검출하기 위해서
P-net은 12x12x3 크기의 작은 이미지를 입력 받음
컨볼루션만 거침 (Full connected Layer X)
face classification(얼굴인지 아닌지) 영역을 나타내는 박스 좌측상단 x,y좌표, box width, box heigth 4개의 값 반환(bounding box regression 값)과
양쪽 눈과 입꼬리, 코의 x,y좌표를 나타내는 10개의 landmark localization 값을 결과로 리턴
피라미드에서 input을 받아서 12x12크기의 윈도우로 스캔해서 얼굴을 찾음
얼굴을 찾았으면 사이즈와 좌표를 원래 크기로 resize
찾은 박스를 대상으로 Non-Maximum-Suppression과 bouding box regression을 적용 가장 높은 확률의 박스만 남김

R-net




R-Net은 P-Net을 통해 얻은 box_list 중에서 진짜 얼굴을 추려내 bounding box regression을 더 정교하게 수행한다. 앞서 구한 box를 24x24 크기로 resize하고 R-Net을 통과

P–net의 경우 위치정보를 잃는 것을 방지하기 위해 FC레이어 제외하고 Conv만 구성
but, R-net은 정교하게 만드는 역할을 수행하기 위해 FC레이어 사용
R-net에서 산출된 box를 resize한다음 NMS와 BBR 적용
-> O-net으로 전달

O-net

R-Net에서 찾아낸 박스들을 48x48 크기로 resize한 뒤 input으로 제공
필터의 크기를 키우면서 Conv레이어와 FC레이어를 거친다
세종류의 output을 산출 -> 최종 Face Detection, Face Alignment 결과 값이 된다.


다른 end-to-end 모델과는 다르게 네트워크의 구조가 비슷하고 ouput도 동일하다.


MTCNN에 사용한 사전학습 모델(Pretrained model)

본 프로젝트에서 Facenet을 사용하기 위해 2가지 pre-trained 모델을 사용


Parameter
20170512-110547
20180402-114759
임베딩 사이즈
128D
512D
이미지 표준화
이미지당
고정
기본 학습률
0.1
0.05
Optimizer
RMSProp
Adam
거리 측정법
유클리드
코사인













